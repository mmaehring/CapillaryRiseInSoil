{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43164661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b20ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 3.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4b0df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x * 2 # N / cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e110da2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013379975262099492"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.random.rand()/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "680780b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20a671aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_measured = abs(y + 0.025*np.random.randn(len(y))) # don't do this\n",
    "y_error = np.array([(0.005) + np.random.rand()/500 for i in range(len(y_measured))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ca9d4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31190020e-03, 1.01190959e+00, 1.99200854e+00, 3.02098252e+00,\n",
       "       3.97642765e+00, 4.99427896e+00, 5.99081569e+00])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "545b9b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0418697 , 0.0257431 , 0.04335565, 0.02978778, 0.04454821,\n",
       "       0.04182307, 0.02623164])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5091c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = lambda x, k: k*x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0329d",
   "metadata": {},
   "source": [
    "$y(t) = a*x + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0a3a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(hook, x, y, sigma=y_error, p0=[1.5]) # function, x_value, y_value, error_y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c52c9d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eccb0cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed6f5e5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function curve_fit in module scipy.optimize.minpack:\n",
      "\n",
      "curve_fit(f, xdata, ydata, p0=None, sigma=None, absolute_sigma=False, check_finite=True, bounds=(-inf, inf), method=None, jac=None, **kwargs)\n",
      "    Use non-linear least squares to fit a function, f, to data.\n",
      "    \n",
      "    Assumes ``ydata = f(xdata, *params) + eps``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    f : callable\n",
      "        The model function, f(x, ...). It must take the independent\n",
      "        variable as the first argument and the parameters to fit as\n",
      "        separate remaining arguments.\n",
      "    xdata : array_like or object\n",
      "        The independent variable where the data is measured.\n",
      "        Should usually be an M-length sequence or an (k,M)-shaped array for\n",
      "        functions with k predictors, but can actually be any object.\n",
      "    ydata : array_like\n",
      "        The dependent data, a length M array - nominally ``f(xdata, ...)``.\n",
      "    p0 : array_like, optional\n",
      "        Initial guess for the parameters (length N). If None, then the\n",
      "        initial values will all be 1 (if the number of parameters for the\n",
      "        function can be determined using introspection, otherwise a\n",
      "        ValueError is raised).\n",
      "    sigma : None or M-length sequence or MxM array, optional\n",
      "        Determines the uncertainty in `ydata`. If we define residuals as\n",
      "        ``r = ydata - f(xdata, *popt)``, then the interpretation of `sigma`\n",
      "        depends on its number of dimensions:\n",
      "    \n",
      "            - A 1-D `sigma` should contain values of standard deviations of\n",
      "              errors in `ydata`. In this case, the optimized function is\n",
      "              ``chisq = sum((r / sigma) ** 2)``.\n",
      "    \n",
      "            - A 2-D `sigma` should contain the covariance matrix of\n",
      "              errors in `ydata`. In this case, the optimized function is\n",
      "              ``chisq = r.T @ inv(sigma) @ r``.\n",
      "    \n",
      "              .. versionadded:: 0.19\n",
      "    \n",
      "        None (default) is equivalent of 1-D `sigma` filled with ones.\n",
      "    absolute_sigma : bool, optional\n",
      "        If True, `sigma` is used in an absolute sense and the estimated parameter\n",
      "        covariance `pcov` reflects these absolute values.\n",
      "    \n",
      "        If False (default), only the relative magnitudes of the `sigma` values matter.\n",
      "        The returned parameter covariance matrix `pcov` is based on scaling\n",
      "        `sigma` by a constant factor. This constant is set by demanding that the\n",
      "        reduced `chisq` for the optimal parameters `popt` when using the\n",
      "        *scaled* `sigma` equals unity. In other words, `sigma` is scaled to\n",
      "        match the sample variance of the residuals after the fit. Default is False.\n",
      "        Mathematically,\n",
      "        ``pcov(absolute_sigma=False) = pcov(absolute_sigma=True) * chisq(popt)/(M-N)``\n",
      "    check_finite : bool, optional\n",
      "        If True, check that the input arrays do not contain nans of infs,\n",
      "        and raise a ValueError if they do. Setting this parameter to\n",
      "        False may silently produce nonsensical results if the input arrays\n",
      "        do contain nans. Default is True.\n",
      "    bounds : 2-tuple of array_like, optional\n",
      "        Lower and upper bounds on parameters. Defaults to no bounds.\n",
      "        Each element of the tuple must be either an array with the length equal\n",
      "        to the number of parameters, or a scalar (in which case the bound is\n",
      "        taken to be the same for all parameters). Use ``np.inf`` with an\n",
      "        appropriate sign to disable bounds on all or some parameters.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "    method : {'lm', 'trf', 'dogbox'}, optional\n",
      "        Method to use for optimization. See `least_squares` for more details.\n",
      "        Default is 'lm' for unconstrained problems and 'trf' if `bounds` are\n",
      "        provided. The method 'lm' won't work when the number of observations\n",
      "        is less than the number of variables, use 'trf' or 'dogbox' in this\n",
      "        case.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "    jac : callable, string or None, optional\n",
      "        Function with signature ``jac(x, ...)`` which computes the Jacobian\n",
      "        matrix of the model function with respect to parameters as a dense\n",
      "        array_like structure. It will be scaled according to provided `sigma`.\n",
      "        If None (default), the Jacobian will be estimated numerically.\n",
      "        String keywords for 'trf' and 'dogbox' methods can be used to select\n",
      "        a finite difference scheme, see `least_squares`.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    kwargs\n",
      "        Keyword arguments passed to `leastsq` for ``method='lm'`` or\n",
      "        `least_squares` otherwise.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    popt : array\n",
      "        Optimal values for the parameters so that the sum of the squared\n",
      "        residuals of ``f(xdata, *popt) - ydata`` is minimized.\n",
      "    pcov : 2-D array\n",
      "        The estimated covariance of popt. The diagonals provide the variance\n",
      "        of the parameter estimate. To compute one standard deviation errors\n",
      "        on the parameters use ``perr = np.sqrt(np.diag(pcov))``.\n",
      "    \n",
      "        How the `sigma` parameter affects the estimated covariance\n",
      "        depends on `absolute_sigma` argument, as described above.\n",
      "    \n",
      "        If the Jacobian matrix at the solution doesn't have a full rank, then\n",
      "        'lm' method returns a matrix filled with ``np.inf``, on the other hand\n",
      "        'trf'  and 'dogbox' methods use Moore-Penrose pseudoinverse to compute\n",
      "        the covariance matrix.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        if either `ydata` or `xdata` contain NaNs, or if incompatible options\n",
      "        are used.\n",
      "    \n",
      "    RuntimeError\n",
      "        if the least-squares minimization fails.\n",
      "    \n",
      "    OptimizeWarning\n",
      "        if covariance of the parameters can not be estimated.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    least_squares : Minimize the sum of squares of nonlinear functions.\n",
      "    scipy.stats.linregress : Calculate a linear least squares regression for\n",
      "                             two sets of measurements.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    With ``method='lm'``, the algorithm uses the Levenberg-Marquardt algorithm\n",
      "    through `leastsq`. Note that this algorithm can only deal with\n",
      "    unconstrained problems.\n",
      "    \n",
      "    Box constraints can be handled by methods 'trf' and 'dogbox'. Refer to\n",
      "    the docstring of `least_squares` for more information.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> from scipy.optimize import curve_fit\n",
      "    \n",
      "    >>> def func(x, a, b, c):\n",
      "    ...     return a * np.exp(-b * x) + c\n",
      "    \n",
      "    Define the data to be fit with some noise:\n",
      "    \n",
      "    >>> xdata = np.linspace(0, 4, 50)\n",
      "    >>> y = func(xdata, 2.5, 1.3, 0.5)\n",
      "    >>> np.random.seed(1729)\n",
      "    >>> y_noise = 0.2 * np.random.normal(size=xdata.size)\n",
      "    >>> ydata = y + y_noise\n",
      "    >>> plt.plot(xdata, ydata, 'b-', label='data')\n",
      "    \n",
      "    Fit for the parameters a, b, c of the function `func`:\n",
      "    \n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata)\n",
      "    >>> popt\n",
      "    array([ 2.55423706,  1.35190947,  0.47450618])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'r-',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "    \n",
      "    Constrain the optimization to the region of ``0 <= a <= 3``,\n",
      "    ``0 <= b <= 1`` and ``0 <= c <= 0.5``:\n",
      "    \n",
      "    >>> popt, pcov = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5]))\n",
      "    >>> popt\n",
      "    array([ 2.43708906,  1.        ,  0.35015434])\n",
      "    >>> plt.plot(xdata, func(xdata, *popt), 'g--',\n",
      "    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
      "    \n",
      "    >>> plt.xlabel('x')\n",
      "    >>> plt.ylabel('y')\n",
      "    >>> plt.legend()\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(curve_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246b457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f533b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x, s1, s2, v1, v2: s1*s2*x + v1 + v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634810d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
